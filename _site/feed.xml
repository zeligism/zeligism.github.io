<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-08-07T16:07:23+04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zeligism</title><subtitle>Personal blog. I write down some of the conversations I have with myself inside my head.</subtitle><entry><title type="html">Consistency</title><link href="http://localhost:4000/2022/03/02/Consistency.html" rel="alternate" type="text/html" title="Consistency" /><published>2022-03-02T02:18:19+04:00</published><updated>2022-03-02T02:18:19+04:00</updated><id>http://localhost:4000/2022/03/02/Consistency</id><content type="html" xml:base="http://localhost:4000/2022/03/02/Consistency.html">&lt;p&gt;The idea of a world view in AI is very important. If you want to simulate an autonomous agent that interacts with the world in a non-trivial manner, then we can say that the agent has to maintain a “world-view”.&lt;/p&gt;

&lt;h4 id=&quot;world-view&quot;&gt;World-view&lt;/h4&gt;
&lt;p&gt;This world-view should contain as much info about the world as possible in order to be efficient—maybe even the entire history of the observations of the world in case memory is limitless. However, not only is memory storage a constraint, but so are memory access and computing power. If memory is limitless somehow, then can we really access it efficiently? Can we take a memory and process it within the agent in a meaningful duration of time? It might be theoritcally possible using some abstract mathematical model that we are not aware of. Assuming memory storage is finite, memories can be further compressed and indexed as they are stored. Compression is obviously an advantage when memory is finite, and indexing is natural given that we need to access memories somehow (and not necessarily access them exactly). So, how are memories compressed and indexed, then? One thing for sure is that context can play a key role in these two processes. I believe an important part of memory (all of it?) is stored in a sequential or programmatic manner, i.e. large memories are compressed as the output of much shorter programs. This way, you can compress infinite strings into a finite program (i.e. algorithm). Heck, there is no such thing as an infinite string that cannot be stored as the output of some program. To see how this is true, think about how you would describe writing your infinite string. Then, your description itself is the program (or the constraints of an implied program understood from context) that generates this infinite string. This is an interesting observation because we could imagine an infinite string that is indescribable in finite words or self-destructive in some sense (self-contradictory, for example), but remember that such strings are not “computable” so they are not the output of a meaningful program. (I’m not well-versed in theoretical computer science, so I could be wrong.)&lt;/p&gt;

&lt;h4 id=&quot;programs&quot;&gt;Programs&lt;/h4&gt;
&lt;p&gt;When you introduce programs, you will then have to introduce interpreters because the same program can be interpreted differently by different agents. When it comes to language, the interpretation is up to the community of agents that is using it. Language construction and interpretation is distributed in some sense; it is not local to a single agent and it evolves as a whole within all the participating agents together as there is no single truth to language interpretation. This allows language to be stable and well-interpretable among the majority of agents without having a central authority on language. This could be the case under some assumptions, of course. It could be the case because knowledge about language is communicated regularly among all of the agents and large variations are usually suppressed (frowned upon, actually) or just slightly adjusted on the go. Even though adjustments are local to the agent (the feedback comes only from the neighboring agents in the communication network), the agents could potentially converge to approximately the same knowledge at the end. (I don’t have a proof for that, but I believe it’s possible to prove it given some additional technical assumptions. For example, one assumption could be the maintenance of a grammar by the community using that language.) In the same manner, we can have a distributed kind of memory that can process some form of a program description in a distributed way, and then generate outputs independently, verify the outputs, and then adjust interpretation through consensus. The interpretation should be able to reconstruct the relevant parts of the sensory inputs (or an intermediary description of it) as perfectly as possible. This compression / interpretation process can be hierarchical such that it is multi-step and intermediary results can be used in other processes. Once the agents reach a stable compression-interpretation scheme, they can store memories as accurately as possible in the shortest form possible. What remains is accessing this particular memory through an index.&lt;/p&gt;

&lt;h4 id=&quot;its-all-a-dream&quot;&gt;It’s All a Dream&lt;/h4&gt;
&lt;p&gt;Indexing is the context-relevant part of the story. When we say “index”, we’re not really talking about a number, or a memory address. We’re talking about a signal that evokes a memory in a smooth manner given some memory state (slightly changing the signal given that memory state can still evoke similar kinds of memories). The signal could be a picture of a scene that you saw or a specific tone you heard during that memory you want to retrieve. Recalling a memory is not all obvious, as we seem to be able to recall memories without a reconstructable internal brain activity/signal. I might be wrong, especially if that internal signal could be exactly described somehow by the person, in which case there does exist a reconstructable brain signal (think about a neuron that represents a very specific property). Recalling a memory is similar to a program that runs in the brain—a search program, to be specific—so it is not all that different from other “programs” running in the brain. So far, terms like “program”, “description” , and “algorithm” seem to be describing the same phenomenon in the brain. The brain has an automatic recall feature, where a sensation can involuntarily remind you of something correlated with it, potentially completely irrelevant or just relevant to either the sensation or the context or their combination. This feature can be exploited to perform a sort of a progressively-selective indexing routine. We can start with a seed signal (a sensation, a thought, or a memory) and start actively recalling memories from that seed, and then select the relevant memories and try to recall finer details in the same fashion iteratively until we converge to what we believe to be the target memory we want to recall (which might not necessarily be an actual memory that we had but a made up one that was formed through a brainwash. You first have to believe that you can recall the target memory—that it is in your brain— given some sort of a “meta-description/signal” of it, which can be vague or wrong. You can’t recall a memory that didn’t happen, so you generate it and thus know that it is fake. But wouldn’t recalling a memory that have indeed happened be the same? Don’t we simply “re-generate” actual memories while assuming that they are real?)&lt;/p&gt;

&lt;h4 id=&quot;guts&quot;&gt;Guts&lt;/h4&gt;
&lt;p&gt;This convergence process is clearly not as simple as it sounds as there are no guarantees that it can happen in finite time given the conditions described. One way we can enforce convergence to this recall process is to evaluate the relevance of the memory we recalled. The memory could be very relevant, and may as well feel like it’s true in the sense that it happened—or is just true by gut feeling. This “gut feeling”, I believe, is the qualia byproduct of the evaluation mechanism that estimates the convergence of the recall process, or simply estimates the truthiness of a thought. If your gut feeling is a conflicted and uneasy feeling, then you’re brain is basically saying that you haven’t converged to a stable memory or state of mind given the query you’re evaluating (recalling a memory or resolving the meaning and implication of a particular statement, for instance.) A strong gut feeling will tell you that you have a strong instinctive reason to believe in the result of your query. The query is the source of conflict that was introduced either by yourself or by an external source of information. Further explaining and understanding the emergence of this gut feeling, beyond the fact that it feels as elementary as the sense of a smell or a color, is completely out of my expertise. But the creation of a query that provokes gut feeling could probably be only associated with (or evoked by) native instinctive needs such as curiosity, survival, reproduction, etc. These instinctive needs could have probably been achieved via evolution—or perhaps by something more structured and elaborate. Who knows.&lt;/p&gt;

&lt;h4 id=&quot;time-devours-life&quot;&gt;Time Devours Life&lt;/h4&gt;
&lt;p&gt;Ok, so far, we have tried to describe the concept of a world-view in an intelligent agent and how the agent can access information from it, but we haven’t yet explained anything about the dynamics of this procedure. For example, how does the world-view changes with each access or with time? Can we assume that the brain has the same structure and that it processes two consecutive “moments” in the same exact manner? The brain does have the ability to tell which moment came before, what happened and what didn’t, what might happen, and what might have happened if something else happened, which is like peeking into another timeline where such a thing did actually happen. But I believe that the brain does not have a “clock”, so to speak. It only creates chains of events that are marked by their temporal positions with respect to some significant event of which the date or timestamp had been explicitly memorized (e.g. your birth, your school years, etc.). Sometimes, it’s difficult to recall which year a particular event happened in your life, or whether one event happened before the other (think about what year in college you took a particular course, or how fast time moves in some scenarios vs. how slow it seems to move in others). The temporal order is only relevant when there is an interesting pattern. Who cares whether you yawned or scratched your head and whether you did it before brushing your teeth or after before sleeping. These are very trivial events that could be totally forgotten about and perhaps even believed to have not happened at all when asked about—let alone give their temporal order—and, surely, absolutely nothing will change in case you remembered the temporal order of these events, unless someone recorded that information and decided to quiz you on it for a million dollar (damn, that would totally suck). Seems like time is only important in the sense that it can only be “consumed” by “going forward”, and what is left behind in the back is something that “happened” for sure, regardless of which came before which (that would be figured out by the brain if it had been important). Thinking about it poetically, it is like time consumes the future and generates observables, which are the only things that we know that “are” for sure. Everything else is uncertain in this world. Even the things that we observe are only as good as our observations themselves, whether they are sense data or measurements. It is much like the process of discovering a mathematical theorem. I mean, that’s why it’s called “discovering a theorem” because it was already there and we just merely observed that it is consistent with our axioms.&lt;/p&gt;

&lt;h4 id=&quot;consistency&quot;&gt;Consistency&lt;/h4&gt;
&lt;p&gt;Now if you connect the whole thing together and try to squeeze it all into one grand picture, you do get some fundamental ideas behind the maintenance of a world-view. We said that memories could be seen as distributed programs that take a seed signal or a description and produce a sequence of signals. The signals converge if the memory exists and can be recalled, where convergence is evaluated by gut feeling. Also, there is no explicit temporal ordering in this world-view. The sequence of signals produced in this process dictates the temporal order, not the other way around. So what do we take from that? Probably the fact that “consistency” is key. Consistency is paramount to world-view, probably for the same reason that it is for math, science, and any other discipline that is based on axiomatic principles. Without consistency, memories cannot be compressed well and cannot be recalled reliably. Also, without consistency, temporal order would be distorted and probably collapse. So what we can take away is that the world-view is maintained by minimizing inconsistencies as much as possible, where inconsistencies can be succinctly defined as “contradictory observations”, e.g. observations that say that such and such has the property of being something and not being it. These are usually found in the edge cases, where prior knowledge have to be refined in order to maintain consistency. Inconsistencies can be dealt with either by deleting one observation—acknowledging the fact that we observed wrongly—or by “adding”  details to the observations (e.g. adding conditions, “something is X at one moment, but could be Y at another”). Proceeding like this, our world-view becomes more and more consistent, allowing us to have a better expectation of the future (which might be one of the main objectives of the brain). This is assuming we live in a stable, consistent world (well, as long we have science and not magic, I guess we do).&lt;/p&gt;

&lt;h4 id=&quot;self-consistency&quot;&gt;“Self”-Consistency&lt;/h4&gt;
&lt;p&gt;We still haven’t attempted to explain the way agents should interact with the world given this world-view, and why the heck people have different world-views if the process of maintaining one is as simple as “eliminate inconsistencies”. Well, to answer the second question first, it is because of the gut feeling-like factors that are controlled by genetics, as well as the process of inconsistency elimination itself. People can eliminate inconsistencies differently, and sometimes even still achieve the same world-view. So the interesting question is how agents interact with the world. This is a very interesting question, and it is perhaps the crux of this essay, despite being not so central to the idea of a world-view per se. This is what I believe:
&lt;strong&gt;Agents interact with the world in a manner that maintains their world-view consistency&lt;/strong&gt;.
There is nothing particularly deep about that statement, I know, but I do think it’s deep. The reason why I think it’s deep is because in this framework, it seems like the agent’s identity is intertwined with the world’s identity, so the agent sees itself as a “thing” in this world: a thing which it could completely control, much like peeping into the world through a spiritual hole which is the “self”, or, put simply, “playing a video game”. The existence of the source of decisions and the engine of our interactions can literally be anywhere. It only needs this channel which is somewhere in the brain. It might even be the case that all consciousnesses exist in a realm where they are somehow interconnected. Sure, that’s stepping into sci-fi territory, but prove me wrong. Looking at it this way, you start to feel kinda detached from your worldly “self”. The brain has full control of what happens in the world, but doesn’t have full control of its inputs—the inputs that come from that thing over there in the realm of “free will”, consciousness, and whatnot. You know what I mean?&lt;/p&gt;

&lt;h4 id=&quot;rewards-curiosity-etc&quot;&gt;Rewards, Curiosity, Etc.&lt;/h4&gt;
&lt;p&gt;Anyway, this is kinda bullshit. We know that the brain’s behavior can be explained well by other simple concepts such as reward-maximization, curiosity, etc. But in my opinion, these can still be described in the aforementioned framework. Curiosity can be a part of the inconsistency elimination process given that the agent have the ability to generate elements in its world-view that were not observed before per se, and thus the agent might feel like it has the need to verify the modified—but in some parts imaginary—world-view that it now has. Also, I think that reward-maximization is a subset of inconsistency elimination. Reward-maximization is a special case when the agent sees that it wants the rewards, but it is not a special case when the agent might see itself as not deserving of the reward or avoiding it for some psychological reason (and thus some rewards could be conditioned by the self to paradoxically evoke negative feelings as well). In fact, in most cases, inconsistency elimination and reward-maximization are synonymous to each.&lt;/p&gt;

&lt;h4&gt;~&lt;/h4&gt;
&lt;p&gt;In the end, I think that what the agent wants depends on genetic needs as well as goals created through the process of maintaining the consistency of a world-view. This is the agent-driven (internal) dynamics. As for the environment-driven (external) dynamics, lower total energy along a trajectory is preferred, which gives rise to conciseness. Thus, the intelligent agent will minimize the extent in which the constraints of the environment are violated (consuming the lowest energy) while maximizing the consistency of its world-view (achieving best accuracy). Consistency and conciseness might even be two faces of the same coin.&lt;/p&gt;</content><author><name></name></author><summary type="html">The idea of a world view in AI is very important. If you want to simulate an autonomous agent that interacts with the world in a non-trivial manner, then we can say that the agent has to maintain a “world-view”.</summary></entry><entry><title type="html">A Stupid Definition of Intelligence</title><link href="http://localhost:4000/2021/10/14/Intelligence.html" rel="alternate" type="text/html" title="A Stupid Definition of Intelligence" /><published>2021-10-14T02:18:19+04:00</published><updated>2021-10-14T02:18:19+04:00</updated><id>http://localhost:4000/2021/10/14/Intelligence</id><content type="html" xml:base="http://localhost:4000/2021/10/14/Intelligence.html">&lt;p&gt;Intelligence is a relative property in the sense that one is more intelligent if: 1) one has “truer expectations” about the world, 2) one converges towards such expectations using a “shorter path”, i.e. with a lesser amount of action, such as energy or time or both. One can imagine combining the two conditions by augmenting the action to the expectation somehow, e.g. as a regularizer. The definition can be more meaningful by introducing more dimensions through deconstructing the two properties of intelligence to more layman terms, especially the second property of action. For example, we can compare the intelligence of two agents in a constrained action space (e.g. limited time, resources, etc). What about “truer expectations”? What does it actually mean?&lt;/p&gt;

&lt;p&gt;Thinnk of expectation as the realization of a world event. It depends on the way we model these things in our brains. “Truthiness” here is measured based on the difference between the “expected” realization (the world-view we had, so to speak) and the “actual” realization (the thing that actually happened and is part of history now, perhaps in the form of data). So, in this sense, “truthiness” itself is &lt;em&gt;not&lt;/em&gt; necessarily the “truth” because it is solely based on &lt;em&gt;the perspective in which this “actual realization” is observed and stored as data in the brain&lt;/em&gt;. However, in the limit of truthiness, we can have only two values (or directions to go to): true or false (or 1 and 0, doesn’t matter). In other words, if we are certain about the truthiness of an event, then we can know for sure whether our expectations are true or false because of boolean logic. This is the case where the axioms in math are absolutely true events by nature of construction, so expectations follow given an implication or a reduction mechanism. Errors and uncertainties are nonexistent in this framework.&lt;/p&gt;

&lt;p&gt;When you introduce uncertainties, you can always go back to more fundamental, certain piece of knowledge from which your current knowledge follows. Then, you can reconsider it and slightly adjust it in order to find a truer body of knowledge overall. This is similar, in a broad sense, to when Einstein discovered a more general (and truer, in this sense) theory than Newton’s. In fact, Newton’s theory is true for almost all everyday-life physics, but Einstein’s theory is true for strictly more situations than Newton’s is. Nonetheless, Newton is still considered to be very intelligent—maybe not any less intelligent than Einstein, so it is not only about truthiness here, it is also about having the truest expectation by consensus of what truthiness constitute of (for example, at the time of Newton, his theory was the truest expectation of a physical theory), as well as who was the first and quickest to have such expectations and communicated them efficiently. This can be applied on so many levels, but in this example the definition of intelligence is applied in a broad sense.&lt;/p&gt;

&lt;p&gt;Ok, but does communication constitute intelligence? One could argue that some savants have the ability to see and understand things that normal humans cannot possibly fathom. Sure, it might be interesting to ponder the fact that “the theory of everything” might be in someone’s brain right now who will never be able communicate it to us, for example, but we simply cannot measure what we do not observe, so that someone might remain as intelligent as they were before the theory of everything came to their mind. Thus, communication should constitute “observable” intelligence, or rather observable anything really. (Well, unless we can decode brain signals for that matter).&lt;/p&gt;

&lt;p&gt;Consider this intelligence comparison test between two agents. We assume that both scenarios are identical except for the brains of the agents. We put each agent on an identical and non-trivial island. The agent that survives longer wins, but we cannot observe anything until the game finishes, i.e. one agent dies. The more intelligent agent is supposed to survive longer (on average, roughly speaking). However, the agents did not have to communicate anything in order for us to deduce who is more intelligent. Therefore, communication does constitute intelligence but not in the restricted sense of normal human communication. We can generalize communication to include the usage of any media to convey information. However, the agent can convey information regarding its own intelligence, such as its survival, but it does not have to. This means that there are simple facts about the universe that we may never be able to observe, including the extreme intelligence of the guy who discovered the theory of everything in his garage but couldn’t convey it to anyone.&lt;/p&gt;

&lt;p&gt;Intelligence is a complicated concept to define rigorously. This post tries to define intelligence in the broadest sense possible as a relative property in terms of two quantities: truthiness and action. Truthiness could be described as the “consistency with respect to some prior knowledge”, and action could be described as “the amount of work done, or planned to be done, in order to achieve such consistency”. Then, intelligence is the extent in which an agent can be more consistent with less action. It is further desirable to describe intelligence with respect to solving a specific category of problems, such as solving physics and math problems vs. solving a social problem with your company. In this manner, we can refine the definition of intelligence for specific instances of behavior given some explicit constraints on the setting.&lt;/p&gt;</content><author><name></name></author><summary type="html">Intelligence is a relative property in the sense that one is more intelligent if: 1) one has “truer expectations” about the world, 2) one converges towards such expectations using a “shorter path”, i.e. with a lesser amount of action, such as energy or time or both. One can imagine combining the two conditions by augmenting the action to the expectation somehow, e.g. as a regularizer. The definition can be more meaningful by introducing more dimensions through deconstructing the two properties of intelligence to more layman terms, especially the second property of action. For example, we can compare the intelligence of two agents in a constrained action space (e.g. limited time, resources, etc). What about “truer expectations”? What does it actually mean?</summary></entry><entry><title type="html">Never Ask a Mathematician to Prove it</title><link href="http://localhost:4000/2021/05/05/MathJokes.html" rel="alternate" type="text/html" title="Never Ask a Mathematician to Prove it" /><published>2021-05-05T02:18:19+04:00</published><updated>2021-05-05T02:18:19+04:00</updated><id>http://localhost:4000/2021/05/05/MathJokes</id><content type="html" xml:base="http://localhost:4000/2021/05/05/MathJokes.html">&lt;p&gt;&lt;em&gt;[Warning: bad jokes ahead!]&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Mathematician: Honey, please, I beg you… don’t leave me alone! I love you!&lt;/p&gt;

&lt;p&gt;Wife: Then prove it to me!&lt;/p&gt;

&lt;p&gt;Mathematician: Sure. Let ε &amp;gt; 0. There exists δ &amp;gt; 0 such tha–&lt;/p&gt;

&lt;p&gt;Wife: OMG JUST FORGET IT.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A mathematician was hanging out in the neighborhood of a closed subspace. He fell off.&lt;/p&gt;

&lt;p&gt;Meanwhile, another mathematician was walking continously through an open neighborhood. He is still walking.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Mathematician 1: I’m not what I used to be.&lt;/p&gt;

&lt;p&gt;Mathematician 2: Then you say you are not who you were?&lt;/p&gt;

&lt;p&gt;Mathematician 1: Yes, that is correct.&lt;/p&gt;

&lt;p&gt;Mathematician 2: Then when were you you? Or when will you be you?&lt;/p&gt;

&lt;p&gt;Mathematician 1: Well, I am me, at least at the very moment I said it.&lt;/p&gt;

&lt;p&gt;Mathematician 2: But if whom you said is you isn’t you now nor before, then you can never be exactly you because there are infinitely many moments where the you who said is not you were in fact you or will be you, so you are not you.&lt;/p&gt;

&lt;p&gt;Mathematician 1: Fuck.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A logician once tried to tell a funny joke. He failed and concluded that his “funny joke is not funny.” He died in an infinite self-recursion.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Two successful businessmen mathematicians had a shady business based on duplication of money on demand. They were once asked whether they were Nigerian king magicians or something. They said “Nah, we’re just Banach and Tarski.”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;What does a string theorist cowboy say when he rides his horse?&lt;/p&gt;

&lt;p&gt;“Calabi-Yeeeehau!”&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;α-mathematicians at the bar&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Real Analyst: I like my women real smooth.&lt;/p&gt;

&lt;p&gt;Group theorist: I like my women normal.&lt;/p&gt;

&lt;p&gt;Ring theorist: Screw normal, I like my women ideal.&lt;/p&gt;

&lt;p&gt;Algebraist: I like my women isomorphic to my wife.&lt;/p&gt;

&lt;p&gt;Logician: I like my women iff my wife.&lt;/p&gt;

&lt;p&gt;Geometrist: I like a cute woman.&lt;/p&gt;

&lt;p&gt;Combinatorialist: I like to count my women.&lt;/p&gt;

&lt;p&gt;Differential geometrist: I like dem curves.&lt;/p&gt;

&lt;p&gt;Statistician: I like my women average and in large numbers.&lt;/p&gt;

&lt;p&gt;Probability theorist: I like my women almost everywhere.&lt;/p&gt;

&lt;p&gt;Functional Analyst: I like Hilbert.&lt;/p&gt;

&lt;p&gt;Optimization scientist: If her lips shits, I’ll smash.&lt;/p&gt;

&lt;p&gt;Theoretical physicist: WTF? Well, I like my women symmetric.&lt;/p&gt;

&lt;p&gt;Cosmologist: As for me, I like “black holes”.&lt;/p&gt;

&lt;p&gt;Topologist: The more holes, the better.&lt;/p&gt;

&lt;p&gt;Number theorist: Can she make a Shepherd’s π with Euler-Mascheroni and cheese on the side?&lt;/p&gt;

&lt;p&gt;Theoretical computer scientist 1: I like my women complete. Turing complete.&lt;/p&gt;

&lt;p&gt;Theoretical computer scientist 2: I like it hard. NP-hard.&lt;/p&gt;

&lt;p&gt;Deep learning engineer: I like it deep and fast.&lt;/p&gt;

&lt;p&gt;Machine learning engineer: But you should stop early. Gotta minimize the risks.&lt;/p&gt;

&lt;p&gt;Machine learning scientist: Bayes’ed woman.&lt;/p&gt;

&lt;p&gt;Computational learning theorist: I like my women probably approximately hot.&lt;/p&gt;

&lt;p&gt;Random matrix theorist: OMG you guys are like soooo randooom.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ً&lt;em&gt;Watch this subspace.&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">[Warning: bad jokes ahead!]</summary></entry><entry><title type="html">Free Doom of Speech</title><link href="http://localhost:4000/2020/12/01/FreeDoomOfSpeech.html" rel="alternate" type="text/html" title="Free Doom of Speech" /><published>2020-12-01T02:18:19+04:00</published><updated>2020-12-01T02:18:19+04:00</updated><id>http://localhost:4000/2020/12/01/FreeDoomOfSpeech</id><content type="html" xml:base="http://localhost:4000/2020/12/01/FreeDoomOfSpeech.html">&lt;p&gt;Freedom of speech is having the right to voice whatever opinion you have. You feel powerful by voicing any opinion you have (and if you have Twitter, you are invincible and can win any argument). It doesn’t feel fair to have your voice censored. You want to be heard because the other person is heard, so why not you? It is only fair to be equal to that other person, right? We want to believe that we are all the same, have the same rights, and deserve the same treatments. Equality is optimal in some sense. If we assume that people want to have the maximum amount of rights but no less than any other person out there, then equality is the only way to do that. Therefore, we feel like it’s only fair to have the right to voice our opinion as much as the other person.&lt;/p&gt;

&lt;p&gt;Free doom of speech is the consequence that follows precisely when the evil desires of society start to manifest in some parts. Humans are constantly on the run looking for opportunities to gain an advantage to achieve what they desire. It is an instinct. They want to hunt better than you to get that sweet sweet T-Rex fillet mignon. They want to be more powerful than you to get stuff from you and then settle in your land and live in your house and then, you know, do stuff to you. They want to get more money than you because they want more stuff than you because you’re ugly and stupid. It is all about the advantage, the upper hand. Call it what you want, but humans are competing for that very thing they desire in every waking moment, and things can get really nasty and ugly really quick, just like it used to be in the past where wars and conflicts were commonplace.&lt;/p&gt;

&lt;p&gt;Nowadays, humans have achieved a mature understanding of moral values that “make sense” and help humans make fair decisions in their daily lives. Thus, we have come to understand the kinds of decisions that are considered “evil” that we should avoid, even though they would let us gain an advantage in getting what we desire. Have you ever stolen a piece of candy as a little kid? You might have, and you are not to be blamed for it because you still didn’t understand the idea of morality very well. You would think that gaining such an “unfair” advantage (i.e. not having to pay for candy while others have to pay) is an opportunity that you should seize to achieve what you desire. The major problem with this is that gaining an advantage for yourself alone might cause an unfair disadvantage for a lot of others. This is why morality is good. It is there to help us regularize our decisions such that they will not cause severe, unfair disadvantages to others.&lt;/p&gt;

&lt;p&gt;I know what you’re thinking. How the fuck does this have anything to do with freedom of speech? Well, the connection is quite subtle, but from the subtlety comes the doom of this “free” kind of speech (as in, you-don’t-have-to-pay-for-candy free). The evil created within society by the lack of morality will eventually create opportunities of abuse in our freedom of speech. People will use freedom of speech itself to gain an unfair advantage by claiming its power of freedom and censoring others from it! For example, I can say this:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“It is my freedom to say whatever I want. Fuck you. You are such a stupid cunt. You are a racist xenophobic bigot that should die, no, you should slowly rot in hell alone. No wait, scratch that. You should slowly rot to death with the hounds of hell as they devour your guts like it’s their birthday. We hate people like you, so how about you get outta here, you worthless excuse for a human being. Oh hey, it is my freedom of speech! You and I have the same power and we both shall exercise our rights to voice our free opinions! Sure, the devil might be jealous of my spiteful unholiness and rotten morals, but I have like 10k retweets on my previous post, so I am invincible.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Have we really forgot that fairness and equality of rights is what lies at the heart of freedom of speech? How come those who use their speech to cancel others are still feeling completely fair about it? Clearly, morality is not a natural law as it only makes sense when humans view themselves functioning as a part of a society that wants to improve “as a whole” (without ignoring the least well-off). But morality can also be a selfish law if one wants it to be.&lt;/p&gt;

&lt;p&gt;I believe one of the main causes of “cancel culture”, which is a more polished sub-term of “free doom of speech”, is that people hold different moral values, to the point where they can actually think that a person they disagree with deserves to die (which is the most severe, almost-always-unfair disadvantage anyone can get). This is the most evil form of of an unfair disadvantage that you can impose on others using the privileges of freedom of speech. That is how the “freedom” of one person turns into the “free doom” of another. That is the state of freedom of speech nowadays. SAD!&lt;/p&gt;</content><author><name></name></author><summary type="html">Freedom of speech is having the right to voice whatever opinion you have. You feel powerful by voicing any opinion you have (and if you have Twitter, you are invincible and can win any argument). It doesn’t feel fair to have your voice censored. You want to be heard because the other person is heard, so why not you? It is only fair to be equal to that other person, right? We want to believe that we are all the same, have the same rights, and deserve the same treatments. Equality is optimal in some sense. If we assume that people want to have the maximum amount of rights but no less than any other person out there, then equality is the only way to do that. Therefore, we feel like it’s only fair to have the right to voice our opinion as much as the other person.</summary></entry><entry><title type="html">Extrapolation as Interpolation</title><link href="http://localhost:4000/2020/11/30/ExtrapolationAsInterpolation.html" rel="alternate" type="text/html" title="Extrapolation as Interpolation" /><published>2020-11-30T00:21:19+04:00</published><updated>2020-11-30T00:21:19+04:00</updated><id>http://localhost:4000/2020/11/30/ExtrapolationAsInterpolation</id><content type="html" xml:base="http://localhost:4000/2020/11/30/ExtrapolationAsInterpolation.html">&lt;p&gt;&lt;em&gt;[These are just personal random thoughts.]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Extrapolation of N observations to K new observations is just an interpolation of N+K observations such that N of them are “known”, and K of them are assumed to be generated or sampled from a generative process that can be (approximately) inferred from the known N observations.&lt;/p&gt;

&lt;p&gt;We can hypothesize a structure that the N observations follow and impose it on the K unobserved points. For example, it helps to know whether the N observations lie in a space that is smooth, 1-Lipschitz, cyclical, bounded, low-dimensional, isomorphic to another space with a known structure, generated by a known process, etc. These things regularize our predictions and minimize the space of possibilities tremendously. They are meta-structures of the space of possible structures that these points lie in, so to speak (and can be so in a hierarchical way). We can also think about it this way: there is a meta-generative process that generates the structure of the space, and then there is another generative process that generates the K points based on this generated structure, so the generative process itself could be parameterized based on another generative process (or probability distribution). Extrapolation can be done by generating the points (K) outside of the interpolation regime (N) assuming they follow the same structure. Then, we can interpolate through all of the points together. The interpolation in the interpolation regime can be done “perfectly” as we know that the N points are given “as is” and are assumed to be “true” in some sense (with some known or unknown margin of error), but in the extrapolation regime it depends on how well the points were generated and how perfectly we can infer the structure from the given N points (which is directly correlated with the degree of error in observing the N points). It could be the case that the structure we need to infer from the N points in order to extrapolate well to the K points is just difficult to figure out. One could say that prediction is a cyclical process of refined induction (inferring the structure) followed by deduction (deriving the predictions given the structure).&lt;/p&gt;

&lt;p&gt;Let’s take a closer look at a real world example. Let’s say that recognizing a new face is done through interpolating the face to the space of face embeddings in our brain. Once we see something that does not immediately resemble a face we know (unconsciousness didn’t work?), we start to include reasoning and thinking in recognizing this face by actively retrieving similar faces or memories of things that resemble this face in a way that involves finer feature recognition (fine details of face, hair, eyes, number of teeth, a specific mark and its position on the face, etc.) Here, we are providing more structure to the space of face embeddings that we know are “true” and can be observed very clearly from the face, and this helps us generate the face embeddings that resemble the face we are observing even more closely. Once we have converged to a face embedding through this iterative recognition-refining process (or whatever you may call it), we either recognize the face by associating it with a very similar face embedding we already have in memory, or we learn this new face embedding and memorize it.&lt;/p&gt;

&lt;p&gt;It could be the case that memorization is possible to the extent that one is able to reliably rewind the recognition process using a “significant” memory as a seed to regenerate this whole process. A “significant” memory is a memory that is significant enough to have been recognized and stored strongly in memory and retrieved by some sort of random access (maybe by “randomly” accessing memories relevant to the observed context, where randomly is loosely defined as the brain does not have a generator of true randomness… or does it?) Retrieving this memory helps retrieving the one that comes after it, and so on.&lt;/p&gt;

&lt;p&gt;Ok, so what does all of this have anything to do with “interpolation as extrapolation”? Well, I don’t really know, but I think the relationship between interpolation and extrapolation is very similar to the one between “remembering” and “learning”. Learning has that extra step the same way extrapolation does.&lt;/p&gt;

&lt;p&gt;Suppose you want to learn two new words. The first one is “charb” and the second is “turenate”. Let me tell you what my brain did when I first read these words (though what I did might be a bit biased because I came up with these words myself). As for the word “charb”, I noticed that it starts with “ch”, then I noticed that it is one of these sweet one-syllable words that are similar to “churn”, “charm”, “chart”, “barb”, “burp”, “carb”, “fart” etc. but starts with “ch”. For some reason, I feel like “churn” is the closest word to it. My brain makes weird decisions, but probably because my brain has 0 knowledge of its meaning, so it chose a word randomly (or maybe because of a slight bias in the way I pronounced it in my brain). I feel like it could be used this way: “he charbed in”, meaning “he interrupted the conversation in a smooth manner”. You know, something like that. But for all we know, this word could mean “swallow quickly, especially a large bite. Ex: my young brother charbed his whole sandwich!” As for the second word, which is “turenate”, I personally couldn’t associate it with many words, but for some reason I thought it sounded similar to “Turing-ate” (Turing is the name of a famous computer scientist and is also a technical term in computer science). Another term I think is close to it is “terminate”. Probably because I’m trying to recall words with similar start-end sounds. So for these reasons, I feel like “turenate” has some sort of a computational, mechanical connotation to it, even though it’s a completely made up word that could literally mean “decorate something with lights, usually a wall. Ex: my family turenated my bedroom and I hate it.” I guess an English native speaker would also find this word similar to “urinate”, but I haven’t used this word a lot in my life, to be honest with you, so it didn’t pop up in my head. But notice how close “urinate” is to “turenate”. The difference is almost the first letter only and they sound very similar, yet I completely missed it.&lt;/p&gt;

&lt;p&gt;All of that is just the first few steps of recognizing a word, where I try to position and relate the word to my own knowledge and memory. Notice that I still never managed to actively memorize these words, and I can only recall them from the context of this whole experience of trying to recognize them. The process of recognizing a word is similar to interpolation in the sense that we are interpolating the word in the space of words we have in memory, given a (learned?) measure or words difference (which in my case used even sensory observations like how the word is pronounced and what it looks like). But really, how and when do we memorize a word? How do we learn it? How do we extrapolate it? That’s a really difficult question. Nobody can claim that they truly understand how the brain learns. It’s just a mystery. There is some connection between the concept of memory and knowledge, though. You remember the things you memorize the same way you know the things you learn. Learning has a lot to do with memorizing and remembering. It might be that, in order to learn something new, we have to hallucinate a memory to remember it as the new thing that we want to learn! Think about it. You can’t learn something new without creating some sort of a situation of having a memory of it in your brain. In other words, you can only learn something given its context (i.e. the things and memories that surround it). I mean, sometimes you have to be able to “generate” or simulate the possible scenarios and tell which ones make the most sense to you based on what you already know (i.e. most similar to what you have already seen).&lt;/p&gt;

&lt;p&gt;Remember my examples about learning a new word. I always look for relevant features to make sense out of these completely new words. These features make logically no sense by the construction of these words themselves, which was a random process (with a little bit of bias from my brain). Still, my brain thinks that these are good features based on my previous experiences of learning words in general. When we use pure logic to learn something, we can only learn what we can directly infer from the facts that we already know, but we will never be able to understand how a completely new, seemingly-irrelevant observation relates to these facts unless we examine the partial similarities between them. This seems to be related to the way we try to understand the generative process of these facts, and then explain the similarities and differences based on this generative process. We can explain the common causes and effects, and summarize them and put them in memory. It’s like going up the ladder of abstraction, and seems like we can always go up and find shorter, more beautiful golden rules-of-thumb for any reasonable phenomenon that we observe in life. I mean, look at us now. We have reached extreme levels of abstractions such that we can explain how the physical world around us behave at a very fine scale with just a few equations. We have gone the extra mile in extrapolating the extrapolations.&lt;/p&gt;

&lt;p&gt;I wish I could be more clear, but this is just a very abstract idea and I still don’t have the right words and thoughts to describe it properly, so I’m just going to end this essay at this point because I feel like if I say anything more after this it will start to become almost indistinguishable from noise.&lt;/p&gt;</content><author><name></name></author><summary type="html">[These are just personal random thoughts.]</summary></entry><entry><title type="html">Barely Legal</title><link href="http://localhost:4000/2020/11/09/BarelyLegal.html" rel="alternate" type="text/html" title="Barely Legal" /><published>2020-11-09T02:15:15+04:00</published><updated>2020-11-09T02:15:15+04:00</updated><id>http://localhost:4000/2020/11/09/BarelyLegal</id><content type="html" xml:base="http://localhost:4000/2020/11/09/BarelyLegal.html">&lt;p&gt;For all \(\epsilon &amp;gt; 0\), the following situation is thought to be morally justified from the western view of dating and consent:&lt;/p&gt;

&lt;p&gt;\(18+\epsilon\) year-old guy: “Hi I’m very attracted to you can we date?”&lt;/p&gt;

&lt;p&gt;\(18-\epsilon\) year-old girl: “Eww creep get away from me you pedo!”&lt;/p&gt;

&lt;p&gt;For infinitely small \(\epsilon\), you can see the absurdity of this rejection, as the age difference would be \(2 \epsilon\), and as you might already know, for any \(\epsilon &amp;gt; 0\), you can find \(\delta\) such that \(2 \epsilon &amp;lt; \delta\). Therefore, creeping out from an arbitrary threshold set heuristically by the law is itself absurd, as the law’s primary intent is to encourage moral behavior, order, reasonability, and justice.&lt;/p&gt;

&lt;p&gt;This strict thresholding is never the perfect idea for implementing any law without eventually facing extreme cases of moral ambiguities where enforcing the law in these particular cases would not necessarily bring justice (e.g. an \(\epsilon\)-underage person doing something illegal for underage people, legal otherwise). For example, compare the legality and the morality of these two situations: \(18 - \epsilon\) year-old girl with a \(20\) year-old guy vs. \(18 + \epsilon\) year-old girl with a \(50\) year-old guy.&lt;/p&gt;

&lt;p&gt;One might be tempted to think that imposing a soft threshold is a natural solution to this problem, like setting a probability distribution as the threshold where the mean would be \(18\), for example. But what distribution to use and how to parameterize it? And how will these rules be imposed by the law on the public and by the public on themselves? Randomly sampling a threshold for each case would still result in equally morally-unsatisfying situations as is the case when using the hard threshold. I mean, when should you call the police? Will you really ask the government to sample a rule from their soft threshold sampler? Will they give each citizen a sampler device to use for each morally-ambiguous situation (which is a brilliant, yet a very stupid idea)?&lt;/p&gt;

&lt;p&gt;Clearly, the problem here is the outliers, and not each individual cases. If a \(44\) year-old guy dated a \(14\) year-old girl, then we can all agree that it’s kinda fucked up in a certain way. I mean she’s still pretty young and doesn’t know shit about life, so it’s difficult to argue that her consent really counts (and in many countries, even her guardians’ consent don’t count). So in the obvious cases, the soft threshold should not be used at all. In general, a morally-ambiguous situation is where we have to start thinking about applying this soft threshold.&lt;/p&gt;

&lt;p&gt;In a morally-ambiguous situation (i.e. an extreme or outlier case), the court can sample a law using a soft threshold, which is naive as we said that it doesn’t improve much on the current system. A better alternative than sampling is weighting. The court can measure the degree to which the law applies in the outlier case by measuring its “distance” (i.e. difference) from a base reference case that is set by the court to which the majority of the public (and the whole court) agrees on the fact that it breaks a particular law unequivocally. The universal measure of difference proposed for a law should also be agreed on similarly. A base reference case is easy to come up for many situations, but designing it such that it breaks the minimum set of laws broken by breaking a particular law, and such that it applies to real life, is easier said than done.&lt;/p&gt;

&lt;p&gt;For the “44 year-old guy vs. \(14\) year-old girl” case, you should assume that, other than the fact that their ages are incompatible and extremely different, they are both completely law-abiding and to the maximum extent. You will quickly realize that our prejudice compels us to prosecute the \(44\) year-old guy to the fullest extent using the most draconian laws available in our hands. However, had the \(14\) year-old girl become a \(18 + \epsilon\) year-old girl instead, we would show slight contempt for the “greedy” girl, slightly distracting our attention from the fact that the \(44\) year-old guy is still a creep and older in the same order of magnitude than the girl (though less of a creep than being with a \(14\) year-old girl, obviously). All of these should not be affected by the base reference case showcasing a situation breaking this particular law. The difference between both situations in the current system of law is maximal. Say the measure is equal to 1 if the cases are maximally different, and 0 if they are minimally different (or exactly the same and not different, in human language). These two cases would be treated very differently by the law since one is “legal”, and the other is “illegal”, even though the difference between these two cases is small by any reasonable measure of difference (both guys are classified as pedos, to start with). However, in the current system of law, the difference between these two cases is 1 because the law measures the difference between cases by their legality. In the hard threshold paradigm, we would also classify the  “\(44\) year-old guy vs. \(18 + \epsilon\) year-old girl” situation as “ewww”-legal or “technically legal but I wish it was slightly illegal”-legal. However, in the soft threshold paradigm, you can simply say that this case is “slightly illegal”, whatever that means. But based on the many similarities between this case and the base reference “law-breaking” case, we can say “hey wait a sec, I feel that there is some moral-ambiguity about this case. The guy is not completely innocent. This case is very close to being illegal, and we should do something about it”. Well, when you can’t enforce the law and prosecute the offender, you can at least impose some regulations and fees that would deter the offender from being in this “slightly illegal” situation, so you’re basically saying to him “Ok legal, but not really, so we’ll annoy you with all these regulations” making the \(44\) year-old guy rethink the attractiveness of his situation (and hopefully its morality) and move on to a more legal, stable situation like a normal human being. It’s kinda like a market (I know humans are not merchandise blah blah blah). The nice thing about fees and regulations is that you can reflect the degree of “offense” in them (i.e. to what extent the law was broken), for example by increasing the fees exponentially with increasing similarity to a reference case. Regulations can actually help guide people toward the more legal situations. Now we can see that the absurdity and the moral-ambiguity of the central case of this essay (the pedo + almost-underage combo case) can be mitigated through some regulations based on extreme age differences.&lt;/p&gt;

&lt;p&gt;So far, the biggest hurdle we face in implementing this mechanism is to find or hypothesize a reference case for each law that can be potentially broken. This is different from what we have, where breaking the law can be simply proven by deduction. This is going to take a lot of effort to establish. Also, instead of having one reference case, we could potentially have multiple references due to the complexity of the case. It gets complicated very, very quickly. But notice that we said that soft thresholding is only necessary in morally-ambiguous situations. Thus, in order to efficiently benefit from this system, it would be better to utilize it on demand by the court and set up new references from past solved cases. The number of morally-ambiguous cases might be infinite, so it makes sense to study the cases that show up in court only. This way, the court can decide whether the \(44\) year-old sugar daddy is a pedo or not, and after that use this case as a reference case of the law in question.&lt;/p&gt;</content><author><name></name></author><summary type="html">For all \(\epsilon &amp;gt; 0\), the following situation is thought to be morally justified from the western view of dating and consent:</summary></entry><entry><title type="html">Memes Are Things</title><link href="http://localhost:4000/2020/06/29/MemesAreThings.html" rel="alternate" type="text/html" title="Memes Are Things" /><published>2020-06-29T00:00:00+04:00</published><updated>2020-06-29T00:00:00+04:00</updated><id>http://localhost:4000/2020/06/29/MemesAreThings</id><content type="html" xml:base="http://localhost:4000/2020/06/29/MemesAreThings.html">&lt;p&gt;Memes are just an easily reproducible “signal” that communicates a certain relatable idea or thought. Memes could come in many forms, including words, pictures, videos, gestures, face expressions, or any other signal that we can “get”.&lt;/p&gt;

&lt;p&gt;That’s it. There is nothing special about memes. They are only ubiquitous for the very fact that their definition is so ambiguous and vague, they occupy an extremely large variety of signals that we consume daily. People are hesitant to call certain jokes “memes” because they want to reserve that common notion of memes to something else that was born out of the images-with-captions kind of memes, but that’s not always representative of memes as we know them. I believe I can give a (somewhat) comprehensive definition of (Internet) memes because I lived through some of the early eras of the Internet (90s + 00s). Let me give you some examples of what I think are memes.&lt;/p&gt;

&lt;p&gt;For example, I think being Rick Roll’ed is one of the most classic memes on the Internet. Dramatic animals are also memes. The notion of “trolling” was extremely meme-worthy since everybody experienced it and already get it, so it was turned into one of the most famous memes and probably marked the transition to modern day memes. Dad jokes are also memes. Why not? You could easily create a dad joke meme by writing a dad joke on an image of a man who looks like the typical funny-wannabe dad. You can even generalize dad jokes that way and call them “dad memes”. (Go ahead, you don’t even have to give me credits for it.)&lt;/p&gt;

&lt;p&gt;Some of the early memes that even preceded trolling memes—and in fact catalyzed their growth—are the images-with-captions kind of memes, which are simply images with funny two-liner jokes, with the second line being the punchline (and the first line being an introductory mundane line, or an intriguing title, or something like that). It’s just a joke with a punchline that you can’t tell without showing the image. It’s an image joke, sort of. The image can be reused if it vaguely or absurdly describes a situation that happens a lot (think stock photos), and so the meme could be reproduced abstractly without showing the image itself. Just mentioning the meme’s name in the right situation is enough.&lt;/p&gt;

&lt;p&gt;One more complicated example is the following. Sometimes your friend does something unique that only he/she/it does. Let’s say your stupid friend likes to say something cheesy like “cool beans” or “awesome sauce”. You could easily create a “meme” out of that, not in the usual sense but abstractly. You have an abstract image of the funny fact that your friend uniquely and repeatedly says this stupid line. You know that whenever your friend does that thing, everybody who’s aware of the situation would unconsciously form that abstract image, so if you follow it with a punchline and complete the picture, your would form an abstract form of a meme that occupy space and time! Ok skip the space and time part, I mean a meme that is delivered in a abstract, non-static form. Images are static, but videos are non-static, for example (though could be called static from a computer’s point of view, right?)&lt;/p&gt;

&lt;p&gt;My point is that &lt;strong&gt;memes are a generalization of jokes&lt;/strong&gt;, among other complex social constructs (such as rhetoric). Memes are usually fun, or at least relatable, because you simply can’t create a boring meme. I mean, it was interesting to whoever created it at the very least. Also, some things look like memes but aren’t. For example, depending on your definiton, “&lt;em&gt;Stay calm and carry on&lt;/em&gt;” is not a meme in and of itself, but a meme could easily be—and was, in fact—created out of it. To make my stance clear and well-grounded, I will provide some characteristics of jokes that are highly in common with memes, which memes seem to cover in some more general, abstract sense:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Relevance&lt;/strong&gt;. Jokes and memes both work well when the consumer is a person who is aware of the main content such that they are ready to consume the punchline or receive the material as expected from the producer. Relevance could also be called “acceptability” or “agreeability”.
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;Truthiness&lt;/strong&gt;. Truth of the material presented increases acceptance and validity. (Actually, when you think more carefully about it, truthiness is correlated with relevance but less general as a characteristic, so truthiness is not really necessary but quite common in memes and jokes alike).&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Absurdity&lt;/strong&gt;. The more absurd or unexpected the punchline, the higher the “fun factor”, which is a factor that correlates with attention, interactiveness, and eventually acceptance as well (ordered in a causative sense). It could be said that absurdity helps pump up the relevance of the content, much like how controversial opinions often get a larger share of attention than it should.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Communicability&lt;/strong&gt;. Memes should be easily communicated. If you create a meme that is 10-pages long, or a meme that is a 30-min gif, then it’s going to fail as a meme or even be recognized as one. Though it could still be a meme to your (naive) eyes. That also falls within the realm of rhetoric and consensus of thoughts.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reproducibility&lt;/strong&gt;. Memes should be easily reproducible. That’s why we’re having a ton of images-with-captions in the social media era. Images became very easily reproducible, and now we’re seeing a surge of gif-able memes because gifs started to become easily reproducible as photo-editing and photo-sharing softwares became more accessible and powerful.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The interesting thing about memes is that they behave like organisms. Yes, we can actually study the dynamics of memes by modeling them as abstract organisms with some weird survival strategies. Basically, you can model them like this: memes are ideas that continue to exist based on their relevance (fitness) in their host environments (humans), and can reproduce as information in abstract media (e.g. bits, files, images, gifs in computers, and thoughts, gestures, and memory in the human brain) and communicated by the hosts via these media. Notice that this model involves all three characteristics of jokes. The most important variable here is relevance, as it dictates how the memes will survive and what communication channels and reproduction methods they will be found attracted to. In fact, the communicability and reproducibility of a meme could also have a direct impact on the relevance of the meme to the host itself, so relevance is very “relevant”. Also, notice that all these variables are completely out of the memes’ control, but those who study memetics religiously will disagree and say that “Memes are gonna take over the world!” Well… Who cares.&lt;/p&gt;

&lt;p&gt;Anyway, I remember taking a class at USC by Leonard Adleman, who is a pretty well-known computer scientist. Well, if you recognize that name, you might immediately think “Wow! I would love to be taught cryptography by a professor like him.” Nope, the class wasn’t on cryptography, and no he didn’t teach us about the RSA encryption at all. In fact, the class was about memes! Prof. Adleman was interested in studying (a more general notion of) memes and why they behave like organisms. He thought that a theory similar to Darwin’s survival theory could be hypothesized about memes (he was aiming too high, to be quite frank).&lt;/p&gt;

&lt;p&gt;The idea that memes are like genes is not new, and, in my humble opinion, it shouldn’t be revived or pursued any further, except perhaps for some mind gymnastics. What’s new about what I have presented here could be seen as the opposite of what those endeavors are seeking to prove—that memes are simple, not grand, not omnipresent, not fundamental, and not anything of that kind. Memes are like “things”. Things are everywhere. They are the building blocks of our lives and universe, and you can’t refute this argument. Do you know why? Because a “thing” is so abstract and vague, it could possibly describe anything. Heck, it’s right there in the sentence I wrote! Of course, a &lt;strong&gt;thing&lt;/strong&gt; could describe any&lt;strong&gt;thing&lt;/strong&gt;, what else would it describe then. In the same spirit, memes are vague, so a precise study or theory about memes is very likely doomed to fail (to predict or to explain) no matter how accurate it is. Studying memes is like studying things. Your theory could be about anything, and it would still be correct, because anything is still a thing, right?&lt;/p&gt;

&lt;p&gt;Look, memes are simple. And they’re vague. Don’t overcomplicate them. If you wish to study memes any further, please do so for the philosophical fun and not for anything serious. Otherwise, your endeavors will be aimless and futile. Bye.&lt;/p&gt;</content><author><name></name></author><summary type="html">Memes are just an easily reproducible “signal” that communicates a certain relatable idea or thought. Memes could come in many forms, including words, pictures, videos, gestures, face expressions, or any other signal that we can “get”.</summary></entry><entry><title type="html">You Don’t Understand I-Don’t-Understand</title><link href="http://localhost:4000/2019/12/18/YouDontUnderstandIDontUnderstand.html" rel="alternate" type="text/html" title="You Don’t Understand I-Don’t-Understand" /><published>2019-12-18T00:00:00+04:00</published><updated>2019-12-18T00:00:00+04:00</updated><id>http://localhost:4000/2019/12/18/YouDontUnderstandIDontUnderstand</id><content type="html" xml:base="http://localhost:4000/2019/12/18/YouDontUnderstandIDontUnderstand.html">&lt;p&gt;This is a pedagogical analysis of not-understanding.&lt;/p&gt;

&lt;p&gt;Teachers often ask students things like this: “Did you understand?”, “Do you have any questions?”, or “Who can answer this question?”, and so on. The problem with these kind of questions is that the teacher is giving the student control over the lecture, and quite often the students are very bad at making the lecture interesting or useful, unless the audience is a small number of extremely interested and cooperative students, like in some graduate courses.&lt;/p&gt;

&lt;p&gt;Depending on the students, the assumed goal of every lecture is well-known; to communicate novel ideas. However, sometimes, the students’ goal is to finish the lecture as soon as possible, disregarding how much they actually understood (i.e. how much of the ideas were communicated successfully). This is typical due to a lot of reasons, many of which are attributed to “unorganized attention”, i.e. having priorities that make one pay more attention to less important subjects and vice versa. For example, if the student was playing a video game and have been fighting a tough boss for a long time and not winning, the student might sit during the lecture brainstorming new strategies to beat this tough boss, in addition to—unsuccessfully, of course—trying to understand the material of the lecture. This is the first point to keep in mind: students may be present, but their minds may be stuck somewhere else. Bring them to the context of the lecture and then ask: “Did you understand?”&lt;/p&gt;

&lt;p&gt;Now the second point is about the “understanding” part. When a student says “Yes, I understand”, they probably don’t understand in your sense, they understand in their probably-naive sense. They might have understood the subject to the extent that enables them to barely pass the next exam, which is a really bad measure of understanding. A key measure of understanding some concept is the ability to explain it (the Feynman definition of understanding). This is a really good measure to test not only the students’s understanding but your own understanding as well. Of course, since you’re the teacher, you‘d better understand the topic you’re explaining. Now, instead of asking “Do you understand?”, ask “Can you explain it?”&lt;/p&gt;

&lt;p&gt;The final point is related to the second in that you try to get into the students’ heads and teach them from there. Don’t let them decide whether things are going well based on their own ways. Whenever you ask a question, ask it not in the sense that you are proof-checking their answers and trying to beat them into failure, but in the sense that you want them to &lt;em&gt;voluntarily&lt;/em&gt; contribute their answers to the lecture. For example, the students might not have any follow-up question, in which case you can stir up their internal reasoning until an apparent contradiction or a missing piece of the puzzle prompts the students to ask interesting questions, and thus remember the concept from the memory of this internal conflict. Questions are a good way to test student’s understanding as well, especially open-ended ones. This is what researchers do; ask themselves interesting open-ended questions and then try to find answers. Try to teach students this skill. Let them ask interesting questions and let them find the answers themselves by guiding them only when necessary. Do it from their perspectives, not yours.&lt;/p&gt;

&lt;p&gt;Once you prepare the students to be able to understand, communicate, and expand on an idea, they will have the ability to use that idea and spread it in a very efficient manner, and thus accelerate the progress of science and spread of knowledge.&lt;/p&gt;</content><author><name></name></author><summary type="html">This is a pedagogical analysis of not-understanding.</summary></entry><entry><title type="html">Arrogant Rationalism</title><link href="http://localhost:4000/2019/12/13/ArrogantRationalism.html" rel="alternate" type="text/html" title="Arrogant Rationalism" /><published>2019-12-13T00:00:00+04:00</published><updated>2019-12-13T00:00:00+04:00</updated><id>http://localhost:4000/2019/12/13/ArrogantRationalism</id><content type="html" xml:base="http://localhost:4000/2019/12/13/ArrogantRationalism.html">&lt;p&gt;Scientists possess more scientific knowledge than the average human. It is implied by the job title itself—scientists, those who “do science”. But science is the thing that contains all known logical knowledge about the universe. Hence, scientists often think that they know more about how the world works, which is kinda true. They also tend to be more logically consistent by the very facts that they are doing science and that science must be logically consistent because without logical consistency, one might as well claim anything one wants.&lt;/p&gt;

&lt;p&gt;It is usually the case that science, which is largely based on rational thinking and the scientific method, is a superior school of thought compared to traditional ones in almost all disciplines. There is something so useful about science that makes people from everywhere adopt it to solve their problems. It’s probably related to its ability to predict and explain an outcome of a phenomenon based on a logically consistent model of that phenomenon. More often than not, this ability makes scientists believe that they have some sort of a bestowed authority on topics that require logical reasoning. They believe that they can always make better choices when it comes to decision making and solving societal problems that can be modeled scientifically. In a way, they’re right. However, experience and guts can triumph over meticulous logical reasoning sometimes, so scientists do fail—naively so in some cases. But seriously why do scientists with their superior rational thinking and the acclaimed scientific method ever fail? Well, I believe scientists fail because either: 1) their logically consistent model is inherently wrong, or (this is usually the case) 2) their model doesn’t apply to the real world very well, which also invalidates some of their explanations about why the modeled phenomenon happened.&lt;/p&gt;

&lt;p&gt;There is a mode of thinking where scientists or rational people hold very tightly and dearly to their “beautiful” theories, which turn out to be prone to naive failures in hindsight. I like to call that &lt;em&gt;arrogant rationalism&lt;/em&gt;. Since this mode of thinking is adopted by a wider subset of people that encompass &lt;em&gt;some&lt;/em&gt; scientists, I will refrain from simply using the vague term “&lt;em&gt;some&lt;/em&gt; scientists” to describe these people. Instead, I will use the term “arrogantly-rational people” as it is more self-descriptive. These people are implicitly arrogant in their assertions and think that the opinions of the non-scientifically-oriented community is, well, bullshit-ish, so to speak. In other words, they think their opinons are based on lies, norms, biases, and/or emotions. These people use science to over-analyze every phenomenon, thinking that their scientifically-sound assumptions are often valid and make sense in the real world. They comment on every topic, thinking that the scientific method and logical consistency of &lt;em&gt;their&lt;/em&gt; world model can solve everything. Unfortunately, life is never that simple. The model that works today for you might not work tomorrow, and some systems are just too damn complex to explain using a few variables (especially and particularly systems that involve human decisions, which include stock markets for example). Also, it is a proven fact that some problems cannot be solved exactly and efficiently at the same time (approximate solutions are more efficient than exact ones). In addition to all of that, most humans eventually make (a lot of) subtle mistakes in their logical reasoning. Sometimes, decisions based on simple hands-on experience can beat the shit out of the classical scientific method. There is nothing wrong with science, it’s just that, sometimes, it is difficult to &lt;em&gt;do science&lt;/em&gt; correctly and apply it to the real world, at least at the current state of science. Think about the science of &lt;em&gt;love&lt;/em&gt;, for example, and how useless it is (I may be wrong though). Maybe one day we will find a rigorous scientific theory of love that let us make reliable predictions and marry people to each other efficiently so everyone can be happy, but right now, nah. I don’t think any scientific model of love would cut it in the real world. This is exactly one of these topics where experience would pat science on the shoulder and say: “Step back, buddy”. In general, rational thinkers face this hurdle when they try analyze complex social phenomena based on logic alone because these phenomena include things like emotions that might come up as an unexplainable structured randomness that siginificatly impact the model’s outcome (again, stock markets is a good example, which is why sentiment analysis is gaining tract in algorithmic trading). When we reach the level where we can scientifically model the human brain exactly, experience might then be explained away from within this model and thus be beaten by any rational thinking based on this model, arrogant or not. For now, such a model seems to be quite far-fetched from the current reality of science, but with the recent advances of AI, the gap to modeling the human brain seems to be slowly, but surely, shrinking.&lt;/p&gt;

&lt;p&gt;So when should arrogantly-rational people stop being overly confident about their theories and experiments? In my opinion, it is healthy to criticize oneself every now and then and assume that one is wrong. Sometimes, the people who are not making any sense to you right now might actually be making a lot of sense when you look at it from a different perspective. Just start with their mindset and come to their conclusions from there, and maybe you will find something along the way. And if you didn’t, well… just move on. There will always be wrong people out there, and you don’t always have to convince everybody on the planet that your world model is more sound and logically consistent than theirs. Remember, your world model might be only true in your mindset alone and not necessarily in others’. Don’t be &lt;em&gt;arrogantly&lt;/em&gt; rational, be &lt;em&gt;wisely&lt;/em&gt; rational.&lt;/p&gt;</content><author><name></name></author><summary type="html">Scientists possess more scientific knowledge than the average human. It is implied by the job title itself—scientists, those who “do science”. But science is the thing that contains all known logical knowledge about the universe. Hence, scientists often think that they know more about how the world works, which is kinda true. They also tend to be more logically consistent by the very facts that they are doing science and that science must be logically consistent because without logical consistency, one might as well claim anything one wants.</summary></entry><entry><title type="html">Deep Success</title><link href="http://localhost:4000/2019/12/12/DeepSuccess.html" rel="alternate" type="text/html" title="Deep Success" /><published>2019-12-12T00:00:00+04:00</published><updated>2019-12-12T00:00:00+04:00</updated><id>http://localhost:4000/2019/12/12/DeepSuccess</id><content type="html" xml:base="http://localhost:4000/2019/12/12/DeepSuccess.html">&lt;p&gt;Some people live a life so that their CV is optimized for success, and do so just to live a successful life, irrespective of things like happiness and stability. It is like they are running a program called “success” that tries to find an optimum (stationary?) lifestyle, where the optimum is Bill Gates or Elon Musk (or something like that).&lt;/p&gt;

&lt;p&gt;The problem with this way of life is that you are optimizing yourself for &lt;em&gt;success&lt;/em&gt; (&lt;em&gt;duh&lt;/em&gt;), where success is a quality that is measured by some standards &lt;strong&gt;people&lt;/strong&gt; set. You can’t simply claim that you are successful because you see yourself so. That’s pathetic and sad. You have to make people, or those standards set by people, decide whether you are successful or not. So being successful does not make sense without relying on people’s opinions. Whose opinion you rely on is something that only you can decide.&lt;/p&gt;

&lt;p&gt;If you rely on your own opinion, then you will very likely end up having delusions of grandeur. If you rely on society’s opinion, then you might end up living like a robot; going through a pre-defined life of typical, boring success. Both options are viable, but something in between ought to hit the sweet spot where you can find the perfect mix of satisfying internal opinions (one’s validation of oneself) and external opinions (others’ validation of oneself).&lt;/p&gt;

&lt;p&gt;Looking at it this way, we are just trying to satisfy everybody’s definition of success—including ours, of course—to varying degrees that depend on complex social relationships. For example, satisfying your family is more important than satisfying a bunch of strangers you saw on the street who wants you to pay for their bus ticket home. The more attached you are to a group of people, the more you want to satisfy their standards of success and seek their validations. People who fall in love, for example, might do some crazy stuff just to seek the validation of their potential partners (i.e. crush) or loved ones since they are very strongly attached to them.&lt;/p&gt;

&lt;p&gt;The problem of achieving &lt;em&gt;success&lt;/em&gt; in the sense that one is living life &lt;em&gt;correctly&lt;/em&gt; (to some extent) requires a healthy mix of validations from many reliable sources. But the older one gets, the smaller the list of external validations one needs. At the end, you will only care about yourself (and perhaps your partner), so success, as others see it, wouldn’t mean shit to you. Your definition of success would be to live through your daily routine as accurately as possible without any interruptions or distractions. In fact, many people regret not spending time with their families (and especially their parents) in their youth, no matter how successful they become. They regret it because their definition of &lt;em&gt;success&lt;/em&gt;, as in succeeding to live a &lt;em&gt;good life&lt;/em&gt;, has changed with time and become less concerned with materialistic achievements and mere number games. Success becomes more complex and deep, and starts to signify something deeper, more long-term, and more meaningful.&lt;/p&gt;

&lt;p&gt;After all, meanings are subjective, and what success means to you may be completely different to another. In fact, that other person might be you in the future. So which kind of success should one thrive to achieve? Think about people who die young, for example. They won’t regret the fun they had and the non-responsible actions they took during their short lives (e.g. smoking and doing drugs, disrespecting people, not following the rules, bad relationship with family, etc.). It is true that they died young, which is a failure that successful people always try to avoid (e.g. Oracles’s CEO), but, in their cases, it might have had nothing to do with what they did (e.g. they died in a plane crash). Therefore, we can safely say that they actually lived a fun, albeit short, life without consequences, and that’s something you can call success! (unless they really preferred to live a longer life, of course.) If you knew you were gonna die young, what kind of successful life would you prefer? Will you still seek fame and money? Will you commit crimes for your own satisfaction if you were to die tomorrow? Or will you cherish your last moments with the people you love the most? What really makes you choose the path you take? And would your view of success change by knowing a little bit of the future and why?&lt;/p&gt;

&lt;p&gt;Perhaps it is your whole collective knowledge that is constantly “correcting” your definitions—and thus, affecting your decisions and actions—when it comes to words like “success”, “happiness”, “fame”, etc. People are (biologically) similar in the way they think, so they usually form similar opinions, but that doesn’t make the different opinions any less correct. I can convince myself that success is about gaining more knowledge, and treat success in every context by that definition, and therefore, aim to gain more knowledge, disregarding money, happiness, and love, which are things that consitute other people’s whole lives. Nobody can prove me wrong; it’s just that my opinion is a radical one and yours is a general one.&lt;/p&gt;

&lt;p&gt;People are social creatures, they are not programmed to live alone. Words like “success” and “fame” do not really make sense in non-social settings, so their meanings are deeply intertwined with they way society perceive those labels and use them. So what is really meant by “deep success” or “meaningful life”? I believe it boils down to the way society views the idealistic individual, where society is a group of people living together and sharing resources (and thus, interact non-trivially by altering others’ welfare). The collection of views converge to the average successful individual in society (with the whole collective group bias, of course), but radical (i.e. outlier) views of success can possibly exist within large subgroups as well, though with a smaller probability as the subgroup gets larger.&lt;/p&gt;

&lt;p&gt;As you can tell, we can’t conclude anything of substantial value about the secrets of deep, meaningful success. This is because there are no secrets, only subjectivity and ambiguity. Nonetheless, I will end this essay with my humble opinion.&lt;/p&gt;

&lt;p&gt;To be successful is to live happily (content with your current state of affairs), sufficiently (have enough resources to maintain your current state of affairs), and actively (play a non-trivial role in society by interacting with other’s state of affairs). You have to be, overall, convinced that your life is good. It might seem exaggerated in simplicity, but it is not. Money helps, but it isn’t really success as we all know; it’s just merchandise with special consensus-based superpowers. Fame is easy to achieve without being successful (do something extremely stupid in public. Boom. You’re famous). Sex gets boring after a while (look at celebrities). What remains is your own (long-term) progress in life and how content you are with it. The three conditions I gave ensure that you are happy and can stay happy in a non-trivial manner (interacting with people ensures that you are not being deluded into a lonely hole of idiosyncratic happiness, so it is a certificate of happiness of some kind that our brains seem to need).&lt;/p&gt;

&lt;p&gt;Overall, if your path in life is always a happy path, and the people you care about can (perhaps indirectly) certify that, then I think you pretty much succeeded in life. Notice that this view of success can also explain the source of the enormous amount of stress and anxiety the Internet-generations experience in their social lives, in which they evaluate and validate their own happiness based on an extremely large pool of not-so-positive opinions and ideologies (i.e. the Internet), so they are under constant pressure to achieve an unrealistic form of success.&lt;/p&gt;</content><author><name></name></author><summary type="html">Some people live a life so that their CV is optimized for success, and do so just to live a successful life, irrespective of things like happiness and stability. It is like they are running a program called “success” that tries to find an optimum (stationary?) lifestyle, where the optimum is Bill Gates or Elon Musk (or something like that).</summary></entry></feed>