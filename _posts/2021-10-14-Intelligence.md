---
layout: post
title:  "A Stupid Analysis of Intelligence"
date:   2021-10-14 02:18:19 +0400
---

Intelligence is a relative property in the sense that one is more intelligent if: 1) one has “truer expectations” about the world, 2) one converges towards such expectations using a “shorter path”, i.e. with a lesser amount of action or work. The definition can be more meaningful by introducing more dimensions through deconstructing the two properties of intelligence to more layman terms, especially the second property of action. For example, we can compare the intelligence of two agents in a constrained action space (e.g. limited time, resources, etc). What about “truer expectations”? What does it actually mean?

Think of expectation as the realization of a world event. It depends on the way we model these things in our brains. “Truthiness” here is measured based on the difference between the “expected” realization (the world-view we had, so to speak) and the “actual” realization (the thing that actually happened and is part of history now). So, in this sense, “truthiness” itself is _not_ necessarily the “truth” because it is solely based on *the perspective in which this “actual realization” is observed and stored as data*. However, in the limit of truthiness, we can have only two values (or directions to go to): true or false (or 1 and 0, doesn’t matter). In other words, if we are certain about the truthiness of an event, then we can know for sure whether our expectations are true or false because of boolean logic. This is the case where the axioms in math are absolutely true events by nature of construction, so "expectations" are logical and follow given an implication or a reduction mechanism. Errors are absolute and uncertainties are nonexistent in this framework.

When you introduce uncertainties, you can always go back to more fundamental, certain piece of knowledge from which your current knowledge follows. Then, you can reconsider it and slightly adjust it in order to find a truer body of knowledge overall. This is similar, in a broad sense, to when Einstein discovered a more general (and truer, in this sense) theory than Newton’s. (It is also kinda similar to backpropagation). In fact, Newton’s theory is true for almost all everyday-life physics, but Einstein’s theory is true for strictly more situations than Newton’s is. Nonetheless, Newton is still considered to be very intelligent---maybe not any less intelligent than Einstein, so it is not only about truthiness here, it is also about having the truest expectation by consensus of what truthiness constitute of (for example, at the time of Newton, his theory was the truest form of a physical theory), as well as who was the first and quickest to have such expectations and communicated them efficiently. This can be applied on so many levels, but in this example the definition of intelligence is applied in a broad sense.

Ok, but does communication constitute intelligence? One could argue that some savants have the ability to see and understand things that normal humans cannot possibly fathom. Sure, it might be interesting to ponder the fact that “the theory of everything” might be in someone’s brain right now who will never be able communicate it to us, for example, but we simply cannot measure what we do not observe, so that someone might remain as seemingly-non-intelligent as they were before the theory of everything came to their mind. Thus, communication should constitute “observable” intelligence, or rather observable anything really. (Well, unless we can decode brain signals for that matter).

Consider this intelligence comparison test between two agents. We assume that both scenarios are identical except for the brains of the agents. We put each agent on an identical and non-trivial island. The agent that survives longer wins, but we cannot observe anything until the game finishes, i.e. one agent dies. The more intelligent agent is supposed to survive longer (on average, roughly speaking). However, the agents did not have to communicate anything in order for us to deduce who is more intelligent. Therefore, communication does constitute intelligence but not in the restricted sense of normal human communication. We can generalize communication to include the usage of any media to convey information. However, the agent can convey information regarding its own intelligence by its actions, such as its survival, but it does not have to. This means that there are simple facts about the universe that we may never be able to observe, including the extreme intelligence of the guy who discovered the theory of everything in his garage but couldn’t convey it to anyone.

Intelligence is a complicated concept to define rigorously. I'm trying to define intelligence in the broadest sense possible as a relative property in terms of two quantities: truthiness and action. Truthiness could be described as the “consistency with respect to some prior knowledge”, and action could be described as “the amount of work done, or planned to be done, in order to achieve such consistency”. Then, intelligence is the extent in which an agent can be more consistent with less action. It is further desirable to describe intelligence with respect to solving a specific category of problems, such as solving physics and math problems vs. solving a social problem with your company. In this manner, we can refine the definition of intelligence for specific instances of behavior given some explicit constraints on the setting.